{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HeadHunter4621/DiffSinger/blob/waffle/inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "H2NPv3kbnymV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b036609-0e8c-4ce4-85f9-1efaa48982f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup Complete\n"
          ]
        }
      ],
      "source": [
        "#@title Install and Preparation\n",
        "from google.colab import drive\n",
        "from IPython.display import clear_output\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "!git clone https://github.com/MLo7Ghinsan/WFL-ASR\n",
        "!wget https://github.com/MLo7Ghinsan/WFL-ASR/releases/download/model_release/ft_model.zip\n",
        "!unzip ft_model.zip -d /content/model\n",
        "%cd /content/WFL-ASR\n",
        "\n",
        "clear_output()\n",
        "print(\"Installing components for inference\")\n",
        "\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "clear_output()\n",
        "print(\"Setup Complete\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYs03gpZBSYV",
        "outputId": "64209a13-ee3c-4606-cee7-86886bc3d612"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "wXl5qwXdvsn_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a623a83f-e10d-4307-a103-a62c006876a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/model/config.yaml\n"
          ]
        }
      ],
      "source": [
        "#@title Apply settings\n",
        "%%writefile /content/model/config.yaml\n",
        "\n",
        "data:\n",
        "  data_dir: /content/Training_dataset\n",
        "  sample_rate: 16000\n",
        "  num_val_files: 10\n",
        "  max_seq_len: null\n",
        "model:\n",
        "  encoder_type: whisper\n",
        "  whisper_model: openai/whisper-base\n",
        "  wavlm_model: microsoft/wavlm-base\n",
        "  freeze_encoder: false\n",
        "  enable_bilstm: true\n",
        "  bilstm_num_layer: 2\n",
        "  enable_dilated_conv: true\n",
        "  dilated_conv_depth: 2\n",
        "  dilated_conv_kernel: 3\n",
        "  enable_duration_prediction: true\n",
        "  duration_head_dim: 128\n",
        "  duration_loss_weight: 0.2\n",
        "  enable_self_attn_polisher: false\n",
        "  self_attn_heads: 2\n",
        "  num_conformer_layers: 2\n",
        "  conformer_heads: 2\n",
        "  conformer_ff_expansion: 2\n",
        "  conformer_kernel_size: 31\n",
        "  conformer_dropout: 0.5\n",
        "  lang_emb_dim: 64\n",
        "  num_languages: 2\n",
        "training:\n",
        "  batch_size: 1\n",
        "  num_workers: 4\n",
        "  learning_rate: 0.0000001\n",
        "  weight_decay: 1.0e-05\n",
        "  label_smoothing: 0.1\n",
        "  max_steps: 500000\n",
        "  val_check_interval: 1000\n",
        "  max_checkpoints: 5\n",
        "  log_dir: /content/logs\n",
        "output:\n",
        "  save_dir: /content/model\n",
        "postprocess:\n",
        "  median_filter: 2\n",
        "  merge_segments: previous\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgTu51YItLnU"
      },
      "source": [
        "English data == 0 as lang_id\n",
        "Japanese data == 1 as lang_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGWa2fGKoBOW"
      },
      "outputs": [],
      "source": [
        "#@title # Single Audio Inference\n",
        "import os\n",
        "audio_file = \"\" # @param {\"type\":\"string\"}\n",
        "lang_id = \"0\" # @param [\"0\",\"1\"]\n",
        "output_lab = audio_file.replace(\".wav\",\".lab\")\n",
        "!python infer.py {audio_file} --checkpoint /content/model/model.pt --config /content/model/config.yaml --output {output_lab} --lang-id {lang_id}\n",
        "clear_output()\n",
        "print(\"Labels generated, check them under \" + output_lab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "SET_mLXjs06N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5432a229-3ac3-40e3-baf1-dd8c4c4839a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels generated, check them under /content/drive/MyDrive/DiffSinger/Waffle/lab\n"
          ]
        }
      ],
      "source": [
        "#@title # Folder Inference\n",
        "folder_path = \"/content/drive/MyDrive/DiffSinger/Waffle\" # @param {\"type\":\"string\"}\n",
        "lang_id = \"1\" # @param [\"0\",\"1\"]\n",
        "lab_folder = True # @param {\"type\":\"boolean\"}\n",
        "#@markdown <font size=\"-1.5\"> Separate the label in their own folder\n",
        "if lab_folder:\n",
        "  output_path = folder_path + \"/lab\"\n",
        "else:\n",
        "  output_path = folder_path\n",
        "!python infer.py {folder_path} --checkpoint /content/model/model.pt --config /content/model/config.yaml --output {output_path} --lang-id {lang_id}\n",
        "clear_output()\n",
        "print(\"Labels generated, check them under \" + output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bCqS_ZNq7lj_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9632d9b-3e9f-4760-b3c6-cdef5f51aa3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  0% 0/17 [00:00<?, ?it/s][INFO] No pre-made boundary file detected, creating a new one\n",
            "[INFO] No pre-made boundary file detected, creating a new one\n",
            "/content/WFL-ASR/correct_label.py:135: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
            "  plt.tight_layout()\n",
            "/content/WFL-ASR/correct_label.py:135: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
            "  plt.tight_layout()\n",
            "/content/WFL-ASR/correct_label.py:136: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
            "  plt.savefig(save_path)\n",
            "/content/WFL-ASR/correct_label.py:136: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
            "  plt.savefig(save_path)\n",
            "  6% 1/17 [01:02<16:43, 62.73s/it][INFO] No pre-made boundary file detected, creating a new one\n",
            " 12% 2/17 [01:06<06:56, 27.80s/it][INFO] No pre-made boundary file detected, creating a new one\n",
            " 18% 3/17 [01:34<06:31, 27.98s/it][INFO] No pre-made boundary file detected, creating a new one\n",
            " 24% 4/17 [01:35<03:48, 17.57s/it][INFO] No pre-made boundary file detected, creating a new one\n",
            " 24% 4/17 [01:43<05:36, 25.85s/it]\n",
            "[INFO] No pre-made boundary file detected, creating a new one\n",
            "[INFO] No pre-made boundary file detected, creating a new one\n"
          ]
        }
      ],
      "source": [
        "#@title Correct Labels\n",
        "#@markdown <font size=\"-1.5\"> Folder path or wav file. Wav and label should be on the same folder\n",
        "folder_path = \"/content/drive/MyDrive/DiffSinger/Waffle\" # @param {\"type\":\"string\"}\n",
        "#@markdown <font size=\"-1.5\"> Save a PNG graph visualization of the label\n",
        "save_png_visualization = True # @param {\"type\":\"boolean\"}\n",
        "if save_png_visualization:\n",
        "  !python correct_label.py {folder_path} --save_plot\n",
        "else:\n",
        "  !python correct_label.py {folder_path}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "eqIKfHh37lj_"
      },
      "outputs": [],
      "source": [
        "#@title # Automatic Inference, Correction and Packing\n",
        "#@markdown This procress automatically unpacks wavs, process, correct and give back the labels inside a drive folder\n",
        "\n",
        "data_zip_path = \"\" # @param {\"type\":\"string\"}\n",
        "lang_id = \"0\" # @param [\"0\",\"1\"]\n",
        "correct_label = True # @param {\"type\":\"boolean\"}\n",
        "#@markdown <font size=\"-1.5\"> Save the original label generated by the WFL\n",
        "save_original_labs= True # @param {\"type\":\"boolean\"}\n",
        "#@markdown <font size=\"-1.5\"> Save a PNG graph visualization of the label\n",
        "save_png_visualization = True # @param {\"type\":\"boolean\"}\n",
        "\n",
        "if correct_label == False:\n",
        "  save_original_labs = False\n",
        "  save_png_visualization = False\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "import datetime\n",
        "from pathlib import Path\n",
        "#Folders\n",
        "temp_folder = Path(\"/content/temp\")\n",
        "temp_folder_export = Path(\"/content/temp_export\")\n",
        "wav_folder = Path(\"/content/wavs\")\n",
        "export_folder = Path(\"/content/drive/MyDrive/WFL/exports\")\n",
        "temp_folder.mkdir(exist_ok=True)\n",
        "temp_folder_export.mkdir(exist_ok=True)\n",
        "wav_folder.mkdir(exist_ok=True)\n",
        "os.makedirs(export_folder,exist_ok=True)\n",
        "\n",
        "#Extracting\n",
        "try:\n",
        "  print(f\"Extracting {data_zip_path}\")\n",
        "  subprocess.run(['7z', 'x', data_zip_path, '-o' + str(temp_folder)], check=True)\n",
        "  print(f\"File {data_zip_path} extracted succesfully to {temp_folder}.\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "  print(f\"Error: {e}\")\n",
        "\n",
        "#Moving\n",
        "print(f\"Moving Wav Files...\")\n",
        "for ext_files in temp_folder.rglob('*'):\n",
        "  if ext_files.is_file():\n",
        "    if ext_files.suffix.lower() in ['.wav']:\n",
        "      dest_folder = wav_folder / ext_files.name\n",
        "      shutil.move(str(ext_files), str(dest_folder))\n",
        "\n",
        "clear_output()\n",
        "print(f\"Moving Complete.\")\n",
        "\n",
        "#Inference\n",
        "print(f\"Inferencing...\")\n",
        "!python infer.py {wav_folder} --checkpoint /content/model/model.pt --config /content/model/config.yaml --lang-id {lang_id}\n",
        "\n",
        "if save_original_labs:\n",
        "  og_label_folder= temp_folder_export / \"original_label\"\n",
        "  og_label_folder.mkdir(exist_ok=True)\n",
        "  print(f\"Saving Original Labels...\")\n",
        "  for ext_files in wav_folder.rglob('*'):\n",
        "    if ext_files.is_file():\n",
        "      if ext_files.suffix.lower() in ['.lab']:\n",
        "        dest_folder = og_label_folder / ext_files.name\n",
        "        shutil.copy(str(ext_files), str(dest_folder))\n",
        "  clear_output()\n",
        "  print(f\"Original Labels Saved.\")\n",
        "\n",
        "#Correct Label\n",
        "if correct_label:\n",
        "  print(f\"Correcting Labels...\")\n",
        "  if save_png_visualization:\n",
        "    !python correct_label.py {wav_folder} --save_plot\n",
        "  else:\n",
        "    !python correct_label.py {wav_folder}\n",
        "  clear_output()\n",
        "  print(f\"Labels Corrected.\")\n",
        "\n",
        "# Move Correct Label and PNG to temp_folder_export\n",
        "print(f\"Moving Labels...\")\n",
        "for ext_files in wav_folder.rglob('*'):\n",
        "  if ext_files.is_file():\n",
        "    if ext_files.suffix.lower() in ['.lab', '.png']:\n",
        "      dest_folder = temp_folder_export / ext_files.name\n",
        "      shutil.move(str(ext_files), str(dest_folder))\n",
        "\n",
        "clear_output()\n",
        "\n",
        "# Pack and Move file to Google Drive\n",
        "print(f\"Packing...\")\n",
        "current_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "archive_name = f\"WFL_Export_{current_time}.zip\"\n",
        "export_path = os.path.join(export_folder,archive_name)\n",
        "try:\n",
        "  print(f\"Creating file: {archive_name}\")\n",
        "  subprocess.run(['7z', 'a', '-mx9', export_path, os.path.join(temp_folder_export, \"*\"),'-r'], check=True)\n",
        "  print(f\"File created successfully at: {export_path}\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "  print(f\"Error creating file: {e}\")\n",
        "\n",
        "#Delete temp folder\n",
        "shutil.rmtree(temp_folder)\n",
        "shutil.rmtree(temp_folder_export)\n",
        "shutil.rmtree(wav_folder)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}